Description:
This project is designed to process specific word counts from a given dataset using PySpark. 
It reads the input data, counts the occurrences of specific words in a specified column, and saves the results in a Parquet format.

Requirements:
Python 3.x
PySpark
Logging
jdk 11 or 17

To get started with this project, clone the repository to your local machine:
https://github.com/Gunasekara98620/assignment_etl.git

build docker image locally or run github actions workflow

To run the project, use the following entry point script:
script/run.sh
